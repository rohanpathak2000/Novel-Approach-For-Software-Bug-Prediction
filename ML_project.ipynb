{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f05cc379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01158b77",
   "metadata": {},
   "source": [
    "### Merging different sets of metrics in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "673b9e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('bug-metrics.csv')\n",
    "df1 = df1.drop(columns = ['nonTrivialBugs', 'majorBugs', 'criticalBugs', 'highPriorityBugs'])\n",
    "df2 = pd.read_csv('change-metrics.csv')\n",
    "df2 = df2.drop(columns = ['nonTrivialBugs', 'majorBugs', 'criticalBugs', 'highPriorityBugs'])\n",
    "df = pd.merge(df1, df2, on = ['classname','bugs'])\n",
    "df3 = pd.read_csv('lin-ent.csv')\n",
    "df3 = df3.drop(columns = ['nonTrivialBugs', 'majorBugs', 'criticalBugs', 'highPriorityBugs'])\n",
    "df = pd.merge(df, df3, on = ['classname', 'bugs'] )\n",
    "df4 = pd.read_csv('complexity-code-change.csv')\n",
    "df = pd.merge(df, df4, on='classname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3557c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(to_convert):\n",
    "    final_list=[]\n",
    "    for i in to_convert:\n",
    "        if i>0.08:\n",
    "            final_list.append(1)\n",
    "        else:\n",
    "            final_list.append(0)\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b92f69",
   "metadata": {},
   "source": [
    "### Separating features and target and feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b8b0d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# --> Debugging statements\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "##print(df.columns)\n",
    "\n",
    "# classname has no use and the unnamed column was created due to a wrongly placed space\n",
    "# will clear it in the future\n",
    "df = df.drop(columns=['classname'])\n",
    "\n",
    "##print(df.dtypes)\n",
    "df.dropna()\n",
    "\n",
    "#Removing the actual bug count column to extract the metrics\n",
    "X = df.loc[:, df.columns != 'bugs']\n",
    "Y = df['bugs']\n",
    "\n",
    "##print(X.dtypes)\n",
    "\n",
    "X = X.apply(pd.to_numeric)\n",
    "##print(X.head())\n",
    "X_asDF = X\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "Y = [(float(i)-min(Y))/(max(Y)-min(Y)) for i in Y]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "620514d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 791, 1: 206})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "freq = Counter(classification(Y))\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d54f1e5",
   "metadata": {},
   "source": [
    "### Extracting top 5 metrics and calculating Ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf2ddb4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5490264761576464\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "feature_scores = {}\n",
    "r_scores = []\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import operator\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    reg.fit(X_train[:,i].reshape(-1,1),Y_train)\n",
    "    feature_scores[i] = reg.score(X_train[:,i].reshape(-1,1),Y_train)\n",
    "\n",
    "sorted_feature_scores = dict( sorted(feature_scores.items(), key=operator.itemgetter(1),reverse=True))\n",
    "\n",
    "\n",
    "dict_items = sorted_feature_scores.items()\n",
    "\n",
    "top_n_metrics = list(dict_items)[:5]\n",
    "#print(top_n_metrics)\n",
    "#print(X_asDF.columns[top_n_metrics[0][0]])\n",
    "\n",
    "list_keys = [x[0] for x in top_n_metrics]\n",
    "#print(list_keys)\n",
    "X_train_for_multiple  = X_train[:,list_keys]\n",
    "X_test_for_multiple  = X_test[:,list_keys]\n",
    "reg.fit(X_train_for_multiple, Y_train)\n",
    "\n",
    "rU = reg.score(X_train_for_multiple, Y_train)\n",
    "print(rU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a591308",
   "metadata": {},
   "source": [
    "### Applying proposed algorithm with Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a25dbcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-a615d6385ede>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpoly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_poly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_poly\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfeature_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1708\u001b[0m                                           self.include_bias)\n\u001b[0;32m   1709\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_input_features_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1710\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_output_features_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1711\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1708\u001b[0m                                           self.include_bias)\n\u001b[0;32m   1709\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_input_features_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1710\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_output_features_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1711\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree = 2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "\n",
    "poly.fit(X_poly,Y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_poly, Y, test_size=0.2, random_state=1)\n",
    "feature_scores = {}\n",
    "r_scores = []\n",
    "\n",
    "# Fitting Polynomial Regression to the dataset\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import operator\n",
    "\n",
    "reg = LinearRegression() \n",
    "for i in range(X_train.shape[1]):\n",
    "    reg.fit(X_train[:,i].reshape(-1,1),Y_train)\n",
    "    feature_scores[i] = reg.score(X_train[:,i].reshape(-1,1),Y_train)\n",
    "\n",
    "sorted_feature_scores = dict( sorted(feature_scores.items(), key=operator.itemgetter(1),reverse=True))\n",
    "\n",
    "\n",
    "dict_items = sorted_feature_scores.items()\n",
    "\n",
    "top_n_metrics = list(dict_items)[:5]\n",
    "#print(top_n_metrics)\n",
    "#print(X_asDF.columns[top_n_metrics[0][0]])\n",
    "\n",
    "list_keys = [x[0] for x in top_n_metrics]\n",
    "#print(list_keys)\n",
    "X_train_for_multiple  = X_train[:,list_keys]\n",
    "X_test_for_multiple  = X_test[:,list_keys]\n",
    "reg.fit(X_train_for_multiple, Y_train)\n",
    "\n",
    "rU = reg.score(X_train_for_multiple, Y_train)\n",
    "print(rU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f5e933",
   "metadata": {},
   "source": [
    "### Proposed Algorithm with Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cc55115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5438538893297045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "feature_scores = {}\n",
    "r_scores = []\n",
    "\n",
    "# Fitting Polynomial Regression to the dataset\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "import operator\n",
    "\n",
    "reg = Ridge() \n",
    "for i in range(X_train.shape[1]):\n",
    "    reg.fit(X_train[:,i].reshape(-1,1),Y_train)\n",
    "    feature_scores[i] = reg.score(X_train[:,i].reshape(-1,1),Y_train)\n",
    "\n",
    "sorted_feature_scores = dict(sorted(feature_scores.items(), key=operator.itemgetter(1),reverse=True))\n",
    "\n",
    "\n",
    "dict_items = sorted_feature_scores.items()\n",
    "\n",
    "top_n_metrics = list(dict_items)[:5]\n",
    "#print(top_n_metrics)\n",
    "#print(X_asDF.columns[top_n_metrics[0][0]])\n",
    "\n",
    "list_keys = [x[0] for x in top_n_metrics]\n",
    "#print(list_keys)\n",
    "X_train_for_multiple  = X_train[:,list_keys]\n",
    "X_test_for_multiple  = X_test[:,list_keys]\n",
    "reg.fit(X_train_for_multiple, Y_train)\n",
    "\n",
    "rU = reg.score(X_train_for_multiple, Y_train)\n",
    "print(rU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b1fd1f",
   "metadata": {},
   "source": [
    "### Calculating weights for the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffb6d8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5357771742550714\n",
      "0.5409279938800345\n",
      "0.5415225079573114\n",
      "0.544483030811822\n",
      "0.5445710278756453\n"
     ]
    }
   ],
   "source": [
    "d = []\n",
    "for i in list_keys:\n",
    "    remaining_features = [j for j in list_keys if j != i ]\n",
    "    X_train_remaining = X_train[:,remaining_features]\n",
    "    # X_test_remaining = X_test[:,remaining_features]\n",
    "    reg.fit(X_train_remaining, Y_train)\n",
    "    train_score = reg.score(X_train_remaining, Y_train)\n",
    "    print(train_score)\n",
    "    d.append(rU-train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bcf9f",
   "metadata": {},
   "source": [
    "### Normalising weights for and predicting the bug proneness index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ea56fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.41427048399891386, 0.34666484682001714, 0.010006655514182719, 0.0]\n"
     ]
    }
   ],
   "source": [
    "norm_d = [(float(i)-min(d))/(max(d)-min(d)) for i in d]\n",
    "print(norm_d)\n",
    "#Weights should be mapped to elements in the list_keys\n",
    "#norm_d are the normalized weights of the n metrics\n",
    "\n",
    "Y_pred = []\n",
    "\n",
    "#print(list_keys)\n",
    "for features_test in X_test:\n",
    "    tot = 0\n",
    "    for (i, wt) in zip(list_keys, norm_d):\n",
    "        tot = tot + features_test[i] * wt\n",
    "    Y_pred.append(tot)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e0b0a",
   "metadata": {},
   "source": [
    "### Printing the predicted and the actual target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04006f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3521 - 0.1111\n",
      "\n",
      "0.0111 - 0.0\n",
      "\n",
      "0.2021 - 0.0\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.009 - 0.0\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0025 - 0.0\n",
      "\n",
      "0.0921 - 0.1111\n",
      "\n",
      "0.0013 - 0.0\n",
      "\n",
      "0.0448 - 0.0\n",
      "\n",
      "0.0037 - 0.0\n",
      "\n",
      "0.0099 - 0.0\n",
      "\n",
      "0.0 - 0.1111\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.014 - 0.0\n",
      "\n",
      "0.0037 - 0.1111\n",
      "\n",
      "0.0087 - 0.0\n",
      "\n",
      "0.005 - 0.0\n",
      "\n",
      "0.0643 - 0.0\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0012 - 0.0\n",
      "\n",
      "0.0194 - 0.0\n",
      "\n",
      "0.0639 - 0.2222\n",
      "\n",
      "0.0012 - 0.0\n",
      "\n",
      "0.0102 - 0.0\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0506 - 0.0\n",
      "\n",
      "0.1514 - 0.0\n",
      "\n",
      "0.0012 - 0.0\n",
      "\n",
      "0.0546 - 0.0\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0012 - 0.0\n",
      "\n",
      "0.0197 - 0.0\n",
      "\n",
      "0.0648 - 0.0\n",
      "\n",
      "0.1201 - 0.0\n",
      "\n",
      "0.0113 - 0.0\n",
      "\n",
      "0.0037 - 0.0\n",
      "\n",
      "0.0255 - 0.0\n",
      "\n",
      "0.0012 - 0.0\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0 - 0.2222\n",
      "\n",
      "0.0187 - 0.0\n",
      "\n",
      "0.2027 - 0.0\n",
      "\n",
      "0.0647 - 0.0\n",
      "\n",
      "0.074 - 0.0\n",
      "\n",
      "0.0119 - 0.0\n",
      "\n",
      "0.1066 - 0.1111\n",
      "\n",
      "0.0218 - 0.0\n",
      "\n",
      "0.3125 - 0.4444\n",
      "\n",
      "0.1895 - 0.4444\n",
      "\n",
      "0.0246 - 0.1111\n",
      "\n",
      "0.0296 - 0.1111\n",
      "\n",
      "0.0037 - 0.0\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0165 - 0.0\n",
      "\n",
      "0.0367 - 0.0\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0286 - 0.0\n",
      "\n",
      "0.0111 - 0.1111\n",
      "\n",
      "0.2536 - 0.2222\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.2406 - 0.5556\n",
      "\n",
      "0.03 - 0.0\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0173 - 0.0\n",
      "\n",
      "0.4786 - 0.1111\n",
      "\n",
      "0.0138 - 0.0\n",
      "\n",
      "0.005 - 0.0\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0025 - 0.0\n",
      "\n",
      "0.1064 - 0.1111\n",
      "\n",
      "0.06 - 0.0\n",
      "\n",
      "0.3611 - 0.3333\n",
      "\n",
      "0.0012 - 0.0\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0 - 0.1111\n",
      "\n",
      "0.1397 - 0.1111\n",
      "\n",
      "0.0087 - 0.0\n",
      "\n",
      "0.0089 - 0.1111\n",
      "\n",
      "0.0087 - 0.0\n",
      "\n",
      "0.0705 - 0.0\n",
      "\n",
      "0.044 - 0.0\n",
      "\n",
      "0.0249 - 0.0\n",
      "\n",
      "0.0488 - 0.0\n",
      "\n",
      "0.0389 - 0.0\n",
      "\n",
      "0.2173 - 0.0\n",
      "\n",
      "0.0087 - 0.0\n",
      "\n",
      "0.0173 - 0.0\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0184 - 0.0\n",
      "\n",
      "0.0012 - 0.0\n",
      "\n",
      "0.005 - 0.0\n",
      "\n",
      "0.0062 - 0.0\n",
      "\n",
      "0.0559 - 0.0\n",
      "\n",
      "0.0125 - 0.0\n",
      "\n",
      "0.0037 - 0.0\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0591 - 0.2222\n",
      "\n",
      "0.197 - 0.1111\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0487 - 0.0\n",
      "\n",
      "0.1063 - 0.0\n",
      "\n",
      "0.0132 - 0.0\n",
      "\n",
      "0.0199 - 0.0\n",
      "\n",
      "0.0012 - 0.1111\n",
      "\n",
      "0.0012 - 0.0\n",
      "\n",
      "0.0498 - 0.2222\n",
      "\n",
      "0.0095 - 0.0\n",
      "\n",
      "0.0071 - 0.0\n",
      "\n",
      "0.0899 - 0.0\n",
      "\n",
      "0.0885 - 0.1111\n",
      "\n",
      "0.1153 - 0.0\n",
      "\n",
      "0.0012 - 0.0\n",
      "\n",
      "0.0012 - 0.0\n",
      "\n",
      "0.1144 - 0.1111\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.012 - 0.0\n",
      "\n",
      "0.0125 - 0.0\n",
      "\n",
      "0.0347 - 0.0\n",
      "\n",
      "0.0012 - 0.0\n",
      "\n",
      "0.0177 - 0.0\n",
      "\n",
      "0.0189 - 0.0\n",
      "\n",
      "0.0609 - 0.2222\n",
      "\n",
      "0.0405 - 0.0\n",
      "\n",
      "0.0123 - 0.1111\n",
      "\n",
      "0.0051 - 0.0\n",
      "\n",
      "0.0641 - 0.0\n",
      "\n",
      "0.0083 - 0.0\n",
      "\n",
      "0.0063 - 0.0\n",
      "\n",
      "0.1033 - 0.2222\n",
      "\n",
      "0.0164 - 0.0\n",
      "\n",
      "0.0163 - 0.0\n",
      "\n",
      "0.3101 - 0.1111\n",
      "\n",
      "0.0101 - 0.0\n",
      "\n",
      "0.0788 - 0.0\n",
      "\n",
      "0.061 - 0.0\n",
      "\n",
      "0.0284 - 0.0\n",
      "\n",
      "0.005 - 0.0\n",
      "\n",
      "0.088 - 0.1111\n",
      "\n",
      "0.0205 - 0.1111\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.3184 - 0.0\n",
      "\n",
      "0.0012 - 0.0\n",
      "\n",
      "0.0085 - 0.0\n",
      "\n",
      "0.0411 - 0.0\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0012 - 0.0\n",
      "\n",
      "0.0167 - 0.0\n",
      "\n",
      "0.0173 - 0.0\n",
      "\n",
      "0.0025 - 0.0\n",
      "\n",
      "0.0722 - 0.0\n",
      "\n",
      "0.061 - 0.0\n",
      "\n",
      "0.0012 - 0.0\n",
      "\n",
      "0.0246 - 0.1111\n",
      "\n",
      "0.0067 - 0.0\n",
      "\n",
      "0.1338 - 0.0\n",
      "\n",
      "0.0099 - 0.0\n",
      "\n",
      "0.057 - 0.2222\n",
      "\n",
      "0.0025 - 0.0\n",
      "\n",
      "0.0233 - 0.0\n",
      "\n",
      "0.076 - 0.0\n",
      "\n",
      "0.0378 - 0.0\n",
      "\n",
      "0.0033 - 0.0\n",
      "\n",
      "0.0105 - 0.0\n",
      "\n",
      "0.0037 - 0.0\n",
      "\n",
      "0.0689 - 0.0\n",
      "\n",
      "0.0773 - 0.0\n",
      "\n",
      "0.1921 - 0.4444\n",
      "\n",
      "0.0523 - 0.0\n",
      "\n",
      "0.1176 - 0.0\n",
      "\n",
      "0.0244 - 0.0\n",
      "\n",
      "0.0063 - 0.0\n",
      "\n",
      "0.2678 - 0.1111\n",
      "\n",
      "1.0 - 0.7778\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0012 - 0.0\n",
      "\n",
      "0.0429 - 0.0\n",
      "\n",
      "0.038 - 0.0\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0025 - 0.0\n",
      "\n",
      "0.4102 - 0.6667\n",
      "\n",
      "0.0113 - 0.0\n",
      "\n",
      "0.0074 - 0.0\n",
      "\n",
      "0.0504 - 0.0\n",
      "\n",
      "0.1149 - 0.0\n",
      "\n",
      "0.0138 - 0.0\n",
      "\n",
      "0.0578 - 0.0\n",
      "\n",
      "0.021 - 0.0\n",
      "\n",
      "0.0112 - 0.0\n",
      "\n",
      "0.0066 - 0.0\n",
      "\n",
      "0.0 - 0.0\n",
      "\n",
      "0.0279 - 0.0\n",
      "\n",
      "0.0124 - 0.0\n",
      "\n",
      "0.195 - 0.3333\n",
      "\n",
      "0.0025 - 0.0\n",
      "\n",
      "0.0711 - 0.0\n",
      "\n",
      "0.1126 - 0.3333\n",
      "\n",
      "0.005 - 0.0\n",
      "\n",
      "0.2062 - 0.1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## The paper doesn't mention normalising again but some values don't lie in the range of 0 to 1\n",
    "## Hence normalising again\n",
    "Y_pred = [(float(i)-min(Y_pred))/(max(Y_pred)-min(Y_pred)) for i in Y_pred]\n",
    "Y_pred_final = [round(i,4) for i in Y_pred]\n",
    "Y_test_final = [round(i,4) for i in Y_test]\n",
    "for(predicted, actual) in zip(Y_pred_final, Y_test_final):\n",
    "    print(f\"{predicted} - {actual}\") \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e4b99e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12481037664445492, 0.0001748539793171428, 0.1298895562815286, 0.0, 0.0013809737117855948]\n"
     ]
    }
   ],
   "source": [
    "## For comparison and visualization \n",
    "# For Linear\n",
    "print(Y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aec6b115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1111111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111, 0.0, 0.0, 0.1111111111111111, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22d2897f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numberOfBugsFoundUntil:</th>\n",
       "      <th>numberOfNonTrivialBugsFoundUntil:</th>\n",
       "      <th>numberOfMajorBugsFoundUntil:</th>\n",
       "      <th>numberOfCriticalBugsFoundUntil:</th>\n",
       "      <th>numberOfHighPriorityBugsFoundUntil:</th>\n",
       "      <th>bugs</th>\n",
       "      <th>numberOfVersionsUntil:</th>\n",
       "      <th>numberOfFixesUntil:</th>\n",
       "      <th>numberOfRefactoringsUntil:</th>\n",
       "      <th>numberOfAuthorsUntil:</th>\n",
       "      <th>...</th>\n",
       "      <th>numberOfPrivateMethods</th>\n",
       "      <th>numberOfPublicAttributes</th>\n",
       "      <th>numberOfPublicMethods</th>\n",
       "      <th>rfc</th>\n",
       "      <th>wmc</th>\n",
       "      <th>CvsEntropy</th>\n",
       "      <th>CvsWEntropy</th>\n",
       "      <th>CvsLinEntropy</th>\n",
       "      <th>CvsLogEntropy</th>\n",
       "      <th>CvsExpEntropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.91310</td>\n",
       "      <td>0.008302</td>\n",
       "      <td>0.014767</td>\n",
       "      <td>0.253257</td>\n",
       "      <td>0.001125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.10349</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.027116</td>\n",
       "      <td>0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.036114</td>\n",
       "      <td>0.041101</td>\n",
       "      <td>37.86060</td>\n",
       "      <td>0.228509</td>\n",
       "      <td>0.106180</td>\n",
       "      <td>1.028400</td>\n",
       "      <td>0.210412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.002711</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>5.86013</td>\n",
       "      <td>0.009105</td>\n",
       "      <td>0.010113</td>\n",
       "      <td>0.143680</td>\n",
       "      <td>0.003485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>13.59600</td>\n",
       "      <td>0.016005</td>\n",
       "      <td>0.025751</td>\n",
       "      <td>0.338602</td>\n",
       "      <td>0.021378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   numberOfBugsFoundUntil:  numberOfNonTrivialBugsFoundUntil:  \\\n",
       "0                        3                                  2   \n",
       "1                        0                                  0   \n",
       "2                       55                                 48   \n",
       "3                        3                                  3   \n",
       "4                       15                                 13   \n",
       "\n",
       "   numberOfMajorBugsFoundUntil:  numberOfCriticalBugsFoundUntil:  \\\n",
       "0                             0                                0   \n",
       "1                             0                                0   \n",
       "2                             6                                4   \n",
       "3                             0                                0   \n",
       "4                             1                                1   \n",
       "\n",
       "   numberOfHighPriorityBugsFoundUntil:  bugs   numberOfVersionsUntil:   \\\n",
       "0                                    0     0                        65   \n",
       "1                                    0     0                         2   \n",
       "2                                    2     1                       120   \n",
       "3                                    0     0                        28   \n",
       "4                                    0     0                        93   \n",
       "\n",
       "    numberOfFixesUntil:    numberOfRefactoringsUntil:   \\\n",
       "0                      4                             0   \n",
       "1                      0                             0   \n",
       "2                     10                             0   \n",
       "3                      4                             0   \n",
       "4                     17                             0   \n",
       "\n",
       "    numberOfAuthorsUntil:   ...  numberOfPrivateMethods  \\\n",
       "0                        8  ...                     0.0   \n",
       "1                        2  ...                     0.0   \n",
       "2                       12  ...                     0.0   \n",
       "3                        5  ...                     0.0   \n",
       "4                        8  ...                     0.0   \n",
       "\n",
       "   numberOfPublicAttributes  numberOfPublicMethods       rfc       wmc  \\\n",
       "0                  0.000000               0.000000  0.000000  0.000000   \n",
       "1                  0.000000               0.000000  0.000000  0.000000   \n",
       "2                  0.000000               0.000905  0.036114  0.041101   \n",
       "3                  0.000000               0.001756  0.002711  0.002314   \n",
       "4                  0.000695               0.000000  0.003749  0.001594   \n",
       "\n",
       "   CvsEntropy  CvsWEntropy  CvsLinEntropy  CvsLogEntropy  CvsExpEntropy  \n",
       "0    10.91310     0.008302       0.014767       0.253257       0.001125  \n",
       "1     1.10349     0.000657       0.001886       0.027116       0.000351  \n",
       "2    37.86060     0.228509       0.106180       1.028400       0.210412  \n",
       "3     5.86013     0.009105       0.010113       0.143680       0.003485  \n",
       "4    13.59600     0.016005       0.025751       0.338602       0.021378  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f04ae94",
   "metadata": {},
   "source": [
    "## Function to classify bug count to 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "526e917c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-46f455570c40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mX_test_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_for_multiple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test_classified\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_for_multiple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train_classified\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "Y_train_classified = classification(Y_train)\n",
    "Y_test_classified = classification(Y_test)\n",
    "Y_pred_classified=classification(Y_pred_final)\n",
    "\n",
    "sm = SMOTE(random_state = 2)\n",
    "X_test_res, Y_test_res = sm.fit_resample(X_test_for_multiple, Y_test_classified)\n",
    "clf.fit(X_train_for_multiple, Y_train_classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbab6844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90       159\n",
      "           1       0.62      0.61      0.62        41\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.76      0.76      0.76       200\n",
      "weighted avg       0.84      0.84      0.84       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test_classified,Y_pred_classified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8406a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting of simple linear regression model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "X_train_for_singlefeat = X_train[:,list_keys[0]]\n",
    "X_test_for_singlefeat = X_test[:,list_keys[0]]\n",
    "X_train_for_singlefeat = X_train_for_singlefeat.reshape(-1,1)\n",
    "reg.fit(X_train_for_singlefeat,Y_train)\n",
    "X_test_for_singlefeat_2d = X_test_for_singlefeat.reshape(-1,1)\n",
    "Y_Predicted = reg.predict(X_test_for_singlefeat_2d)\n",
    "#plt.scatter(X_test_for_singlefeat_2d,Y_test_final)\n",
    "plt.xlabel(\"Actual bug count\")\n",
    "plt.ylabel(\"Predicted bug index\")\n",
    "#Y_test_final_arr = np.array(Y_test_final)\n",
    "#slope,intercept = np.polyfit(Y_test_final_arr,Y_pred_final,1)\n",
    "#Y_intercept = slope*Y_test_final_arr + intercept\n",
    "#plt.plot(X_test_for_singlefeat_2d,Y_Predicted)\n",
    "plt.scatter(Y_test_final,Y_Predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adcf73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting of multiple linear regression\n",
    "\n",
    "reg.fit(X_train,Y_train)\n",
    "Y_Pred_multiplereg = reg.predict(X_test)\n",
    "#plt.plot(Y_test,Y_Predicted_multiplereg)\n",
    "plt.scatter(Y_test,Y_Pred_multiplereg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf5ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting of prosposed model\n",
    "\n",
    "plt.scatter(Y_test_final,Y_pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b1d0b5",
   "metadata": {},
   "source": [
    "## Classificaton report for testing data\n",
    "### Simple Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train_for_singlefeat,Y_train)\n",
    "Y_pred_simple = reg.predict(X_test_for_singlefeat_2d)\n",
    "print(\"Classification report : \")\n",
    "print(classification_report(classification(Y_test), classification(Y_pred_simple)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec68df",
   "metadata": {},
   "source": [
    "### Multiple Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca215fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train,Y_train)\n",
    "Y_pred_multiple = reg.predict(X_test)\n",
    "print(\"Classification report : \")\n",
    "print(classification_report(classification(Y_test), classification(Y_pred_multiple)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91096144",
   "metadata": {},
   "source": [
    "### Proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88785229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       159\n",
      "           1       0.70      0.56      0.62        41\n",
      "\n",
      "    accuracy                           0.86       200\n",
      "   macro avg       0.79      0.75      0.77       200\n",
      "weighted avg       0.85      0.86      0.85       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "reg.fit(X_train_for_multiple,Y_train)\n",
    "Y_pred_proposed = reg.predict(X_test_for_multiple)\n",
    "print(\"Classification report : \")\n",
    "print(classification_report(classification(Y_test), classification(Y_pred_proposed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99001d3",
   "metadata": {},
   "source": [
    "### Applying classification models to the proposed model(5 selected features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc2cea3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB,ComplementNB\n",
    "Y = df['bugs']\n",
    "Y_nb = []\n",
    "print(set(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7cac3603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 632, 1: 632})\n",
      "Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       159\n",
      "           1       0.64      0.51      0.57        41\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.76      0.72      0.73       200\n",
      "weighted avg       0.83      0.84      0.83       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "clf = GaussianNB()\n",
    "sm = SMOTE(random_state = 2)\n",
    "Y_train_classified = classification(Y_train)\n",
    "X_train_res, Y_train_res = sm.fit_resample(X_train_for_multiple, Y_train_classified)\n",
    "print(Counter(Y_train_res))\n",
    "clf.fit(X_train_res, Y_train_res)\n",
    "Y_pred = clf.predict(X_test_for_multiple)\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print(\"Classification report : \")\n",
    "print(classification_report(classification(Y_test), classification(Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c0a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ComplementNB()\n",
    "clf.fit(X_train_for_multiple, classification(Y_train))\n",
    "Y_pred = clf.predict(X_test_for_multiple)\n",
    "print(\"Classification report : \")\n",
    "print(classification_report(classification(Y_test), classification(Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d765b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 632, 1: 632})\n",
      "Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       159\n",
      "           1       0.49      0.54      0.51        41\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.68      0.70      0.69       200\n",
      "weighted avg       0.80      0.79      0.79       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(criterion = \"entropy\", splitter=\"random\",min_samples_split=3)\n",
    "clf.fit(X_train_res, Y_train_res)\n",
    "print(Counter(Y_train_res))\n",
    "Y_pred = clf.predict(X_test_for_multiple)\n",
    "print(\"Classification report : \")\n",
    "print(classification_report(classification(Y_test), classification(Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38756a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91       159\n",
      "           1       0.64      0.61      0.62        41\n",
      "\n",
      "    accuracy                           0.85       200\n",
      "   macro avg       0.77      0.76      0.77       200\n",
      "weighted avg       0.85      0.85      0.85       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver='saga', penalty = 'l2', C = 0.1, random_state=10)\n",
    "clf.fit(X_train_res, Y_train_res)\n",
    "Y_pred = clf.predict(X_test_for_multiple)\n",
    "print(\"Classification report : \")\n",
    "print(classification_report(classification(Y_test), classification(Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70e090ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.78      0.85       159\n",
      "           1       0.47      0.76      0.58        41\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.70      0.77      0.71       200\n",
      "weighted avg       0.83      0.78      0.79       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=35)\n",
    "clf.fit(X_train_res, Y_train_res)\n",
    "Y_pred = clf.predict(X_test_for_multiple)\n",
    "print(\"Classification report : \")\n",
    "print(classification_report(classification(Y_test), classification(Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "72a3c0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       159\n",
      "           1       0.46      0.44      0.45        41\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.66      0.65      0.66       200\n",
      "weighted avg       0.78      0.78      0.78       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfs = RandomForestClassifier(n_estimators=300, criterion = \"gini\")\n",
    "rfs.fit(X_train_res, Y_train_res)\n",
    "Y_pred = rfs.predict(X_test_for_multiple)\n",
    "print(\"Classification report : \")\n",
    "print(classification_report(classification(Y_test), classification(Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ec9483c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.02088787 0.01043805 0.00177681]\n",
      " [0.01401869 0.005      0.         ... 0.05292446 0.01730772 0.05042487]\n",
      " [0.06542056 0.065      0.05263158 ... 0.10292228 0.04406022 0.04115889]\n",
      " ...\n",
      " [0.14953271 0.145      0.10526316 ... 0.61903227 0.91153662 0.50895073]\n",
      " [0.03738318 0.035      0.         ... 0.51903798 0.87449154 0.40012858]\n",
      " [0.02336449 0.01       0.         ... 0.14018949 0.01443694 0.24466886]]\n"
     ]
    }
   ],
   "source": [
    "Counter(Y_train_classified)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4cb3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
